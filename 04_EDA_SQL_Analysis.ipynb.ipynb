{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n",
    "    </a>\n",
    "</p>\n",
    "\n",
    "<h1 align=center><font size = 5>Assignment: SQL Notebook for Peer Assignment</font></h1>\n",
    "\n",
    "Estimated time needed: **60** minutes.\n",
    "\n",
    "## Introduction\n",
    "Using this Python notebook you will:\n",
    "\n",
    "1.  Understand the Spacex DataSet\n",
    "2.  Load the dataset  into the corresponding table in a Db2 database\n",
    "3.  Execute SQL queries to answer assignment questions \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the DataSet\n",
    "\n",
    "SpaceX has gained worldwide attention for a series of historic milestones. \n",
    "\n",
    "It is the only private company ever to return a spacecraft from low-earth orbit, which it first accomplished in December 2010.\n",
    "SpaceX advertises Falcon 9 rocket launches on its website with a cost of 62 million dollars wheras other providers cost upward of 165 million dollars each, much of the savings is because Space X can reuse the first stage. \n",
    "\n",
    "\n",
    "Therefore if we can determine if the first stage will land, we can determine the cost of a launch. \n",
    "\n",
    "This information can be used if an alternate company wants to bid against SpaceX for a rocket launch.\n",
    "\n",
    "This dataset includes a record for each payload carried during a SpaceX mission into outer space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the datasets\n",
    "\n",
    "This assignment requires you to load the spacex dataset.\n",
    "\n",
    "In many cases the dataset to be analyzed is available as a .CSV (comma separated values) file, perhaps on the internet. Click on the link below to download and save the dataset (.CSV file):\n",
    "\n",
    " <a href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/data/Spacex.csv\" target=\"_blank\">Spacex DataSet</a>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sqlalchemy==1.3.9\n",
      "  Downloading SQLAlchemy-1.3.9.tar.gz (6.0 MB)\n",
      "     ---------------------------------------- 0.0/6.0 MB ? eta -:--:--\n",
      "     ------- -------------------------------- 1.0/6.0 MB 7.1 MB/s eta 0:00:01\n",
      "     ------- -------------------------------- 1.0/6.0 MB 7.1 MB/s eta 0:00:01\n",
      "     -------------- ------------------------- 2.1/6.0 MB 3.4 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 2.1/6.0 MB 3.4 MB/s eta 0:00:02\n",
      "     -------------- ------------------------- 2.1/6.0 MB 3.4 MB/s eta 0:00:02\n",
      "     --------------- ------------------------ 2.4/6.0 MB 1.7 MB/s eta 0:00:03\n",
      "     --------------------- ------------------ 3.1/6.0 MB 2.2 MB/s eta 0:00:02\n",
      "     ---------------------- ----------------- 3.4/6.0 MB 1.9 MB/s eta 0:00:02\n",
      "     ---------------------------- ----------- 4.2/6.0 MB 2.2 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 5.2/6.0 MB 2.4 MB/s eta 0:00:01\n",
      "     ----------------------------------- ---- 5.2/6.0 MB 2.4 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 6.0/6.0 MB 2.4 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Building wheels for collected packages: sqlalchemy\n",
      "  Building wheel for sqlalchemy (setup.py): started\n",
      "  Building wheel for sqlalchemy (setup.py): finished with status 'done'\n",
      "  Created wheel for sqlalchemy: filename=SQLAlchemy-1.3.9-cp312-cp312-win_amd64.whl size=1142950 sha256=623175d8fb852ef55ea01324137d0de92dc0575225abaffb023c8dcfd132631c\n",
      "  Stored in directory: c:\\users\\hp\\appdata\\local\\pip\\cache\\wheels\\b3\\1c\\42\\0e26b8d512adc6bce10ff71a05229366b4ccec641cd3b42111\n",
      "Successfully built sqlalchemy\n",
      "Installing collected packages: sqlalchemy\n",
      "  Attempting uninstall: sqlalchemy\n",
      "    Found existing installation: SQLAlchemy 2.0.34\n",
      "    Uninstalling SQLAlchemy-2.0.34:\n",
      "      Successfully uninstalled SQLAlchemy-2.0.34\n",
      "Successfully installed sqlalchemy-1.3.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\HP\\anaconda3\\Lib\\site-packages\\~qlalchemy'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "aext-project-filebrowser-server 4.1.0 requires sqlalchemy>=2.0.29, but you have sqlalchemy 1.3.9 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install sqlalchemy==1.3.9\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the database\n",
    "\n",
    "Let us first load the SQL extension and establish a connection with the database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ipython-sql\n",
      "  Downloading ipython_sql-0.5.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting prettytable (from ipython-sql)\n",
      "  Downloading prettytable-3.16.0-py3-none-any.whl.metadata (33 kB)\n",
      "Requirement already satisfied: ipython in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipython-sql) (8.27.0)\n",
      "Collecting sqlalchemy>=2.0 (from ipython-sql)\n",
      "  Downloading sqlalchemy-2.0.43-cp312-cp312-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting sqlparse (from ipython-sql)\n",
      "  Downloading sqlparse-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: six in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipython-sql) (1.16.0)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipython-sql) (0.2.0)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sqlalchemy>=2.0->ipython-sql) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sqlalchemy>=2.0->ipython-sql) (4.11.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipython->ipython-sql) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipython->ipython-sql) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipython->ipython-sql) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipython->ipython-sql) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipython->ipython-sql) (2.15.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipython->ipython-sql) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipython->ipython-sql) (5.14.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipython->ipython-sql) (0.4.6)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\hp\\anaconda3\\lib\\site-packages (from prettytable->ipython-sql) (0.2.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython->ipython-sql) (0.8.3)\n",
      "Requirement already satisfied: executing in c:\\users\\hp\\anaconda3\\lib\\site-packages (from stack-data->ipython->ipython-sql) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\hp\\anaconda3\\lib\\site-packages (from stack-data->ipython->ipython-sql) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\hp\\anaconda3\\lib\\site-packages (from stack-data->ipython->ipython-sql) (0.2.2)\n",
      "Downloading ipython_sql-0.5.0-py3-none-any.whl (20 kB)\n",
      "Downloading sqlalchemy-2.0.43-cp312-cp312-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------- ----- 1.8/2.1 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  2.1/2.1 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 736.2 kB/s eta 0:00:00\n",
      "Downloading prettytable-3.16.0-py3-none-any.whl (33 kB)\n",
      "Downloading sqlparse-0.5.3-py3-none-any.whl (44 kB)\n",
      "Installing collected packages: sqlparse, sqlalchemy, prettytable, ipython-sql\n",
      "  Attempting uninstall: sqlalchemy\n",
      "    Found existing installation: SQLAlchemy 1.3.9\n",
      "    Uninstalling SQLAlchemy-1.3.9:\n",
      "      Successfully uninstalled SQLAlchemy-1.3.9\n",
      "Successfully installed ipython-sql-0.5.0 prettytable-3.16.0 sqlalchemy-2.0.43 sqlparse-0.5.3\n",
      "Requirement already satisfied: ipython-sql in c:\\users\\hp\\anaconda3\\lib\\site-packages (0.5.0)\n",
      "Requirement already satisfied: prettytable in c:\\users\\hp\\anaconda3\\lib\\site-packages (3.16.0)\n",
      "Requirement already satisfied: ipython in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipython-sql) (8.27.0)\n",
      "Requirement already satisfied: sqlalchemy>=2.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipython-sql) (2.0.43)\n",
      "Requirement already satisfied: sqlparse in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipython-sql) (0.5.3)\n",
      "Requirement already satisfied: six in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipython-sql) (1.16.0)\n",
      "Requirement already satisfied: ipython-genutils in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipython-sql) (0.2.0)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\hp\\anaconda3\\lib\\site-packages (from prettytable) (0.2.5)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sqlalchemy>=2.0->ipython-sql) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from sqlalchemy>=2.0->ipython-sql) (4.11.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipython->ipython-sql) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipython->ipython-sql) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipython->ipython-sql) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipython->ipython-sql) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipython->ipython-sql) (2.15.1)\n",
      "Requirement already satisfied: stack-data in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipython->ipython-sql) (0.2.0)\n",
      "Requirement already satisfied: traitlets>=5.13.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipython->ipython-sql) (5.14.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from ipython->ipython-sql) (0.4.6)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from jedi>=0.16->ipython->ipython-sql) (0.8.3)\n",
      "Requirement already satisfied: executing in c:\\users\\hp\\anaconda3\\lib\\site-packages (from stack-data->ipython->ipython-sql) (0.8.3)\n",
      "Requirement already satisfied: asttokens in c:\\users\\hp\\anaconda3\\lib\\site-packages (from stack-data->ipython->ipython-sql) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\hp\\anaconda3\\lib\\site-packages (from stack-data->ipython->ipython-sql) (0.2.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install ipython-sql\n",
    "!pip install ipython-sql prettytable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv, sqlite3\n",
    "import prettytable\n",
    "prettytable.DEFAULT = 'DEFAULT'\n",
    "\n",
    "con = sqlite3.connect(\"my_data1.db\")\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql sqlite:///my_data1.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DS0321EN-SkillsNetwork/labs/module_2/data/Spacex.csv\")\n",
    "df.to_sql(\"SPACEXTBL\", con, if_exists='replace', index=False,method=\"multi\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:This below code is added to remove blank rows from table**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///my_data1.db\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#DROP THE TABLE IF EXISTS\n",
    "\n",
    "%sql DROP TABLE IF EXISTS SPACEXTABLE;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///my_data1.db\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sql create table SPACEXTABLE as select * from SPACEXTBL where Date is not null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tasks\n",
    "\n",
    "Now write and execute SQL queries to solve the assignment tasks.\n",
    "\n",
    "**Note: If the column names are in mixed case enclose it in double quotes\n",
    "   For Example \"Landing_Outcome\"**\n",
    "\n",
    "### Task 1\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### Display the names of the unique launch sites  in the space mission\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CCAFS LC-40' 'VAFB SLC-4E' 'KSC LC-39A' 'CCAFS SLC-40']\n"
     ]
    }
   ],
   "source": [
    "unique_launch_sites = df['Launch_Site'].unique()\n",
    "\n",
    "# Display unique launch sites\n",
    "print(unique_launch_sites)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Task 2\n",
    "\n",
    "\n",
    "#####  Display 5 records where launch sites begin with the string 'CCA' \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Date Time (UTC) Booster_Version  Launch_Site  \\\n",
      "0  2010-06-04   18:45:00  F9 v1.0  B0003  CCAFS LC-40   \n",
      "1  2010-12-08   15:43:00  F9 v1.0  B0004  CCAFS LC-40   \n",
      "2  2012-05-22    7:44:00  F9 v1.0  B0005  CCAFS LC-40   \n",
      "3  2012-10-08    0:35:00  F9 v1.0  B0006  CCAFS LC-40   \n",
      "4  2013-03-01   15:10:00  F9 v1.0  B0007  CCAFS LC-40   \n",
      "\n",
      "                                             Payload  PAYLOAD_MASS__KG_  \\\n",
      "0               Dragon Spacecraft Qualification Unit                  0   \n",
      "1  Dragon demo flight C1, two CubeSats, barrel of...                  0   \n",
      "2                              Dragon demo flight C2                525   \n",
      "3                                       SpaceX CRS-1                500   \n",
      "4                                       SpaceX CRS-2                677   \n",
      "\n",
      "       Orbit         Customer Mission_Outcome      Landing_Outcome  \n",
      "0        LEO           SpaceX         Success  Failure (parachute)  \n",
      "1  LEO (ISS)  NASA (COTS) NRO         Success  Failure (parachute)  \n",
      "2  LEO (ISS)      NASA (COTS)         Success           No attempt  \n",
      "3  LEO (ISS)       NASA (CRS)         Success           No attempt  \n",
      "4  LEO (ISS)       NASA (CRS)         Success           No attempt  \n"
     ]
    }
   ],
   "source": [
    "cca_launch_sites = df[df['Launch_Site'].str.startswith('CCA')]\n",
    "\n",
    "# Display first 5 such records\n",
    "print(cca_launch_sites.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### Display the total payload mass carried by boosters launched by NASA (CRS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45596\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where Customer is 'NASA (CRS)'\n",
    "nasa_crs_df = df[df['Customer'] == 'NASA (CRS)']\n",
    "\n",
    "# Sum the payload mass for these launches\n",
    "total_payload_mass = nasa_crs_df['PAYLOAD_MASS__KG_'].sum()\n",
    "\n",
    "print(total_payload_mass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### Display average payload mass carried by booster version F9 v1.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2928.4\n"
     ]
    }
   ],
   "source": [
    "# Filter rows where Booster Version is 'F9 v1.1'\n",
    "f9_v11_df = df[df['Booster_Version'] == 'F9 v1.1']\n",
    "\n",
    "# Calculate the average payload mass for these launches\n",
    "average_payload_mass = f9_v11_df['PAYLOAD_MASS__KG_'].mean()\n",
    "\n",
    "print(average_payload_mass)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "\n",
    "##### List the date when the first succesful landing outcome in ground pad was acheived.\n",
    "\n",
    "\n",
    "_Hint:Use min function_ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2015-12-22 00:00:00\n"
     ]
    }
   ],
   "source": [
    "# Convert Date column to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Filter for successful landings on the ground pad\n",
    "successful_ground_pad = df[(df['Landing_Outcome'] == 'Success (ground pad)')]\n",
    "\n",
    "# Find the earliest date of successful ground pad landing\n",
    "first_success_date = successful_ground_pad['Date'].min()\n",
    "\n",
    "print(first_success_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6\n",
    "\n",
    "##### List the names of the boosters which have success in drone ship and have payload mass greater than 4000 but less than 6000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F9 FT B1022' 'F9 FT B1026' 'F9 FT  B1021.2' 'F9 FT  B1031.2']\n"
     ]
    }
   ],
   "source": [
    "# Filter boosters with successful drone ship landing and payload mass between 4000 and 6000 kg\n",
    "filtered_boosters = df[\n",
    "    (df['Landing_Outcome'] == 'Success (drone ship)') & \n",
    "    (df['PAYLOAD_MASS__KG_'] > 4000) & \n",
    "    (df['PAYLOAD_MASS__KG_'] < 6000)\n",
    "]\n",
    "\n",
    "# Get unique booster names\n",
    "booster_names = filtered_boosters['Booster_Version'].unique()\n",
    "\n",
    "print(booster_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 7\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### List the total number of successful and failure mission outcomes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mission_Outcome\n",
      "Success                             98\n",
      "Failure (in flight)                  1\n",
      "Success (payload status unclear)     1\n",
      "Success                              1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Count total successful and failure mission outcomes\n",
    "mission_outcome_counts = df['Mission_Outcome'].value_counts()\n",
    "\n",
    "print(mission_outcome_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 8\n",
    "\n",
    "\n",
    "\n",
    "##### List all the booster_versions that have carried the maximum payload mass, using a subquery with a suitable aggregate function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['F9 B5 B1048.4' 'F9 B5 B1049.4' 'F9 B5 B1051.3' 'F9 B5 B1056.4'\n",
      " 'F9 B5 B1048.5' 'F9 B5 B1051.4' 'F9 B5 B1049.5' 'F9 B5 B1060.2 '\n",
      " 'F9 B5 B1058.3 ' 'F9 B5 B1051.6' 'F9 B5 B1060.3' 'F9 B5 B1049.7 ']\n"
     ]
    }
   ],
   "source": [
    "# Find the maximum payload mass\n",
    "max_payload_mass = df['PAYLOAD_MASS__KG_'].max()\n",
    "\n",
    "# List all booster versions with maximum payload mass\n",
    "boosters_max_payload = df[df['PAYLOAD_MASS__KG_'] == max_payload_mass]['Booster_Version'].unique()\n",
    "\n",
    "print(boosters_max_payload)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 9\n",
    "\n",
    "\n",
    "##### List the records which will display the month names, failure landing_outcomes in drone ship ,booster versions, launch_site for the months in year 2015.\n",
    "\n",
    "**Note: SQLLite does not support monthnames. So you need to use  substr(Date, 6,2) as month to get the months and substr(Date,0,5)='2015' for year.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Month_Name       Landing_Outcome Booster_Version  Launch_Site\n",
      "13    January  Failure (drone ship)   F9 v1.1 B1012  CCAFS LC-40\n",
      "16      April  Failure (drone ship)   F9 v1.1 B1015  CCAFS LC-40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_15620\\3659042462.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  filtered_df['Month_Name'] = filtered_df['Date'].dt.strftime('%B')\n"
     ]
    }
   ],
   "source": [
    "# Convert Date column to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Filter for year 2015 and failure landing outcomes on drone ship\n",
    "filtered_df = df[\n",
    "    (df['Date'].dt.year == 2015) &\n",
    "    (df['Landing_Outcome'] == 'Failure (drone ship)')\n",
    "]\n",
    "\n",
    "# Extract month names\n",
    "filtered_df['Month_Name'] = filtered_df['Date'].dt.strftime('%B')\n",
    "\n",
    "# Select required columns\n",
    "result = filtered_df[['Month_Name', 'Landing_Outcome', 'Booster_Version', 'Launch_Site']]\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 10\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##### Rank the count of landing outcomes (such as Failure (drone ship) or Success (ground pad)) between the date 2010-06-04 and 2017-03-20, in descending order.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Landing_Outcome\n",
      "No attempt                10\n",
      "Failure (drone ship)       5\n",
      "Success (drone ship)       5\n",
      "Controlled (ocean)         3\n",
      "Success (ground pad)       3\n",
      "Failure (parachute)        2\n",
      "Uncontrolled (ocean)       2\n",
      "Precluded (drone ship)     1\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Convert Date column to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Filter dataset between 2010-06-04 and 2017-03-20\n",
    "filtered_df = df[(df['Date'] >= '2010-06-04') & (df['Date'] <= '2017-03-20')]\n",
    "\n",
    "# Count landing outcomes and rank in descending order\n",
    "landing_outcome_counts = filtered_df['Landing_Outcome'].value_counts().sort_values(ascending=False)\n",
    "\n",
    "print(landing_outcome_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference Links\n",
    "\n",
    "* <a href =\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Labs_Coursera_V5/labs/Lab%20-%20String%20Patterns%20-%20Sorting%20-%20Grouping/instructional-labs.md.html?origin=www.coursera.org\">Hands-on Lab : String Patterns, Sorting and Grouping</a>  \n",
    "\n",
    "*  <a  href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Labs_Coursera_V5/labs/Lab%20-%20Built-in%20functions%20/Hands-on_Lab__Built-in_Functions.md.html?origin=www.coursera.org\">Hands-on Lab: Built-in functions</a>\n",
    "\n",
    "*  <a  href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Labs_Coursera_V5/labs/Lab%20-%20Sub-queries%20and%20Nested%20SELECTs%20/instructional-labs.md.html?origin=www.coursera.org\">Hands-on Lab : Sub-queries and Nested SELECT Statements</a>\n",
    "\n",
    "*   <a href=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Module%205/DB0201EN-Week3-1-3-SQLmagic.ipynb\">Hands-on Tutorial: Accessing Databases with SQL magic</a>\n",
    "\n",
    "*  <a href= \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DB0201EN-SkillsNetwork/labs/Module%205/DB0201EN-Week3-1-4-Analyzing.ipynb\">Hands-on Lab: Analyzing a real World Data Set</a>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Author(s)\n",
    "\n",
    "<h4> Lakshmi Holla </h4>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Contributors\n",
    "\n",
    "<h4> Rav Ahuja </h4>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--\n",
    "## Change log\n",
    "| Date | Version | Changed by | Change Description |\n",
    "|------|--------|--------|---------|\n",
    "| 2024-07-10 | 1.1 |Anita Verma | Changed Version|\n",
    "| 2021-07-09 | 0.2 |Lakshmi Holla | Changes made in magic sql|\n",
    "| 2021-05-20 | 0.1 |Lakshmi Holla | Created Initial Version |\n",
    "-->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h3 align=\"center\"> © IBM Corporation 2021. All rights reserved. <h3/>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "prev_pub_hash": "12df46c3b0654f639da96fac3e05f156ee105e47e0c79adacb1892bc327713de"
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
